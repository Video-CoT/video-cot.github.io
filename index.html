<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Uni-Embodied: Towards Unified Evaluation for Embodied Planning, Perception, and Execution">
  <meta property="og:title" content="Uni-Embodied"/>
  <meta property="og:description" content="A benchmark for unified evaluation of planning, perception, and execution in embodied intelligence"/>
  <meta property="og:url" content="https://github.com/linglingxiansen/Uni-Embodied.github.io"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <meta name="twitter:title" content="Uni-Embodied">
  <meta name="twitter:description" content="Benchmarking VLMs for unified embodied intelligence">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Embodied AI, VLM, Benchmark, Planning, Perception, Execution">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Uni-Embodied: Towards Unified Evaluation for Embodied Planning, Perception, and Execution</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Uni-Embodied: Towards Unified Evaluation for Embodied Planning, Perception, and Execution</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Lingfeng Zhang, Yingbo Tang, Xinyu Zheng, Qiang Zhang, Yu Liu, Renjing Xu, Xiaoshuai Hao</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Affiliation TBD<br>Conference Name and Year</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/XXXX.XXXXX.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Supplementary</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/CRH380-CR400/uni-embodied" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/XXXX.XXXXX" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Embodied intelligence is a core challenge in the pursuit of artificial general intelligence (AGI), requiring the seamless integration of <strong>planning, perception, and execution</strong> to enable agents to perform physical tasks effectively. While recent vision-language models (VLMs) have shown strong performance in isolated capabilities, their ability to jointly exhibit all three embodied skills remains unclear, impeding the development of unified embodied systems.
          </p>
          <p>
            In this paper, we propose <strong>Uni-Embodied</strong>, the first comprehensive benchmark designed to evaluate VLMs across the three key dimensions of embodied intelligence: planning, perception, and execution. Our benchmark includes nine diverse tasks—ranging from complex and simple embodied planning to trajectory summarization, map understanding, affordance recognition, spatial pointing, manipulation analysis, and execution in both navigation and manipulation contexts.
          </p>
          <p>
            Extensive experiments on leading open-source and closed-source VLMs demonstrate that current models struggle to achieve balanced performance across all three dimensions. Notably, we observe that enhancing planning and perception often compromises execution, while focusing on execution significantly degrades planning and perception capabilities—revealing fundamental limitations in existing approaches.
          </p>
          <p>
            We further explore strategies such as <strong>chain-of-thought prompting</strong> and <strong>hybrid training</strong> to selectively improve specific embodied capabilities. These findings offer valuable insights for the development of more robust and unified embodied intelligence systems, critical for advancing real-world robotic applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Abstract -->

<!-- You can now continue with your video, carousel, BibTeX, etc. -->

 
